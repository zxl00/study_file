## docker架构图

![docker 架构](https://gitee.com/root_007/md_file_image/raw/master/202306251427725.png)

> 启动容器是通过 `containerd-shim` 去调用 `runc` 来启动容器的，`runc` 启动完容器后本身会直接退出，`containerd-shim` 则会成为容器进程的父进程, 负责收集容器进程的状态, 上报给 containerd, 并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理, 确保不会出现僵尸进程。

## CRI

> CRI(Container Runtime Interface容器运行时接口)，本质上就是k8s定义的一组与容器运行时进行交互的接口，所以只要是实现了这套接口的容器运行时都可以对接到k8s平台上，其中dockershim就是k8s对接docker到CRI接口上的一个垫片实现

![cri shim](https://gitee.com/root_007/md_file_image/raw/master/202306251430417.png)

![dockershim](https://gitee.com/root_007/md_file_image/raw/master/202306141039023.png)

![kubelet cri](https://gitee.com/root_007/md_file_image/raw/master/202306251430490.png)

> - kubelet通过gRPC框架与容器运行时或shim进行通信，其中kubelet作为客户端，CRI shim(也可能是容器运行时本身)作为服务端，当我们使用docker时，在k8s集群中创建一个pod，首先kubelet通过CRI接口调用dockershim，请求创建一个容器，kubelet可以看作一个简单的CRI的client，而dockershim就是接收请求的server，都是内置在kubelet中的，然后dockershim接收到请求后，转化成docker daemon能识别的请求，发送到docker daemon上请求创建一个容器，然后去调用containerd，然后创建containerd-shim进程，最后通过进程去调用runc去真正创建容器
> - CRI定义的API主要包括两个gRPC服务，ImageService和RuntimeService，其中ImageService服务主要负责镜像拉取、查看和删除等操作，RuntimeService则是用来管理pod和容器的生命周期以及与容器交互的调用(exec/attach/port-forward)等操作

## containerd

containerd 是一个工业级标准的容器运行时，它强调**简单性**、**健壮性**和**可移植性**，containerd 可以负责干下面这些事情：

- 管理容器的生命周期（从创建容器到销毁容器）
- 拉取/推送容器镜像
- 存储管理（管理镜像及容器数据的存储）
- 调用 runc 运行容器（与 runc 等容器运行时交互）
- 管理容器网络接口及网络

![containerd 架构](https://gitee.com/root_007/md_file_image/raw/master/202306251439817.png)

![containerd 架构2](https://gitee.com/root_007/md_file_image/raw/master/202306251440727.png)

![image-20230625144116706](https://gitee.com/root_007/md_file_image/raw/master/202306251441747.png)

## cgroup驱动

在 Linux 上，[控制组（CGroup）](https://v1-25.docs.kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-cgroup)用于限制分配给进程的资源。

> - [kubelet](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubelet) 和底层容器运行时都需要对接控制组来强制执行 [为 Pod 和容器管理资源](https://v1-25.docs.kubernetes.io/zh-cn/docs/concepts/configuration/manage-resources-containers/) 并为诸如 CPU、内存这类资源设置请求和限制。若要对接控制组，kubelet 和容器运行时需要使用一个 **cgroup 驱动**。 
>
> - 关键的一点是 kubelet 和容器运行时需使用相同的 cgroup 驱动并且采用相同的配置。

可用的 cgroup 驱动有两个

> - cgroupfs
> - systemd

### cgroupfs驱动

> `cgroupfs`驱动是`kubelet`默认的`cgroup`驱动，当使用`cgroupfs`驱动时，`kubelet`和容器运行时直接对接`cgroup`文件系统来配置`cgroup`

### systemd cgroup驱动

> - 当`systemd`是初始化系统时，不推荐使用`cgroupfs`驱动，因为`systemd`期望系统上只有一个`cgroup`管理器，此外如果使用`cgroup v2`则应该使用`systemd` cgroup驱动取代`cgroupfs`
> - 当某个linux系统发行版使用systemd作为初始化系统时，初始化进程会生成并使用一个root控制组(cgroup)并充当cgroup管理器，systemd与cgroup集成紧密，并将为每个systemd单元分配一个cgroup，因此systemd用作初始化系统，同时使用cgroupfs驱动系统中会存在两个不通的cgroup管理器，同时存在两个cgroup管理器将造成系统中针对可用的资源和使用中的资源出现两个视图，某些情况下，将kubelet和容器运行时配置为使用cgroupfs，但未剩余的进程使用systemd的那些节点在资源压力增大时变得不稳定
> - 当systemd是选定的初始化系统时，缓解这个不稳定问题的方法是针对kubelet和容器运行时将systemd用作cgroup驱动

### 查看系统cgroup驱动

```bash
ps -p 1 -o comm=
```

或者

```bash
ls -l /sbin/init
```

